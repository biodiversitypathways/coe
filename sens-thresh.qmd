---
title: "Analyzing natural area sensitivity thresholds for humans and species diversity in Alberta’s Capital City"
format:
  html:
    grid:
      margin-width: 300px
website:
  navbar:
    - icon: github
      menu:
          - text: Source Code
            href: https://github.com/biodiversitypathways/coe
theme: cosmo
page-layout: article
date: "`r format(Sys.time(), '%d %B, %Y')`"
author: 
  - name: "Alex MacPhail"
    affiliation:
    - "Biodiversity Pathways Ltd."
  - name: "Catherine Shier"
    affiliation:
      - "City of Edmonton"
  - name: "Erin Bayne"
    affiliation:
      - "University of Alberta, Alberta Biodiversity Monitoring Institute"
editor: visual
bibliography: references.bib
nocite: '@*'
toc: true
toc-depth: 3
toc-expand: true
toc-location: left
github: https://github.com/biodiversitypathways/coe
---

![](./assets/yegbanner.jpg){style="float:left`;" fig-alt="YEG Banner" fig-align="center"}

```{r}
#| label: Load packages and data
#| include: false
#| echo: false
#| eval: true
#| warning: false
#| message: false

library(tidyverse)
library(leaflet)
library(wildrtrax)
library(sf)
library(ggridges)
library(scales)
library(kableExtra)
library(plotly)
library(DT)
library(fs)

load('coe.RData')
#save.image('coe.RData')

```

```{r}
#| label: Authenticate to WildTrax and download data
#| include: false
#| echo: false
#| eval: false
#| warning: false
#| message: false

wt_auth()

coe_2024 <- wt_download_report(1750, 'ARU', 'main', T)
coe_ini_2025 <- read_csv("assets/YEG25-InitialSites.csv") |> st_as_sf(coords = c("longitude","latitude"), crs = 4326)

```

# What's all this noise about?

Urban noise is increasingly recognized for its detrimental effects on both human health and biodiversity. This project aims to initiate a long-term monitoring effort to assess the impact of urban noise on natural areas within the City of Edmonton. The goal is to develop a comprehensive framework and actionable tools to reduce noise pollution and support urban biodiversity monitoring, fostering quieter, more sustainable urban environments. This project is in collaboration with the City of Edmonton Arts, Heritage and Nature Experience team, the [University of Alberta](https://www.ualberta.ca) and the [SENSR](sensr.ca) unit of [Biodiversity Pathways Ltd.](https://biodiversitypathways.ca/), itself a national subsidiary of the [Alberta Biodiversity Monitoring Institute](abmi.ca), which is a not-for-profit that tracks changes in wildlife and their habitats across Alberta, working collaboratively to provide ongoing, relevant, and scientifically credible information about our living resources.

::: {style="display: flex; justify-content: center; align-items: center; gap: 20px; padding: 20px;"}
<a href="https://sensr.ca" target="_blank" style="text-decoration: none;"> <img src="SENSRlogo.png" alt="SENSR Logo" style="max-width: 100px; max-height: 100px; object-fit: contain;"/> </a> <a href="https://biodiversitypathways.ca" target="_blank" style="text-decoration: none;"> <img src="BPlogo.png" alt="Biodiversity Pathways" style="max-width: 150px; max-height: 150px; object-fit: contain;"/> </a> <a href="https://www.ualberta.ca/" target="_blank" style="text-decoration: none;"> <img src="UAlberta.png" alt="UofA" style="max-width: 150px; max-height: 150px; object-fit: contain;"/> </a> <a href="https://www.edmonton.ca/city_government/environmental_stewardship/natural-areas" target="_blank" style="text-decoration: none;"> <img src="coelogo.png" alt="COE" style="max-width: 150px; max-height: 150px; object-fit: contain;"/> </a>
:::

::: {.callout-note collapse="true" style="background-color: #f4f4f4; padding: 20px;"}
This report is dynamically generated, meaning its results may evolve with the addition of new data or further analyses. For the most recent updates, refer to the publication date and feel free to reach out to the authors.
:::

# Land Acknowledgement

Edmonton, ᐊᒥᐢᑿᒌᐚᐢᑲᐦᐃᑲᐣ Amiskwaciwâskahikan, is located within Treaty 6 Territory and within the Métis homelands and Métis Nation of Alberta Region 4. We acknowledge this land as the traditional territories of many First Nations such as the Nehiyaw (Cree), Denesuliné (Dene), Nakota Sioux (Stoney), Anishinaabe (Saulteaux) and Niitsitapi (Blackfoot).

# Introduction

Urbanization, driven by globalization and industrialization, leads to higher population densities and significant changes in landscapes (@carnahan1974urbanization, @berry2008urbanization, @davis2015urbanization). However, urbanization also introduces anthropogenic challenges, such as light and noise pollution, which are closely tied to densely populated areas and have well-established negative effects on human, biodiversity (@sordello2020evidence) and ecosystem health. As cities expand, the need for humans to reconnect with nature becomes increasingly critical (@pyle2003nature, @buxton2024mental). This reinforces the need for accessible natural spaces within cities. In response, urban planners are integrating green spaces into cities by creating parks and preserving natural areas (@mata2020bringing). Whether urban green spaces can effectively sustain and represent native biodiversity is still being studied as urbanization evolves. Although managed natural areas and green spaces may offer critical habitats, excessive noise pollution can render these spaces unsuitable for species dependent on quiet environments for communication, reproduction, and survival. Even adaptable species face challenges when urban nature design is incomplete or poorly integrated, affecting their fitness and reproductive success.

Modern urban planning offers an opportunity to address these challenges in a holistic manner. By prioritizing quieter, functional urban spaces through district planning and zoning bylaws, urban designs can reduce noise pollution while offering residents easy access to amenities, including grocery stores, schools, and parks. Public transit improvements indirectly mitigates traffic noise, contributing to healthier urban soundscapes. To reshape urban infrastructure effectively, it is essential to understand the temporal changes and behavioural impacts of noise pollution on both humans and wildlife, which requires continuous, robust environmental monitoring. Advances in acoustic and image monitoring technologies now make such environmental assessments more feasible and cost-effective (@buxton2018pairing). However, current monitoring practices often rely on resource-intensive methods, such as moving equipment by trucks, which can contradict environmental stewardship principles.

In Alberta's 2021 Census, 82.3% of the population resided in urban areas, with a significant concentration in census metropolitan areas (CMAs) like Edmonton. The City of Edmonton has committed to enhancing its biodiversity through various strategic initiatives, including the [Natural Connections Strategic Plan, 2007](https://www.edmonton.ca/sites/default/files/public-files/assets/PDF/Natural_Connections_-_Strategic_Plan_JUNE_09.pdf?cb=1738466394) and the [Biodiversity Action Plan, 2009](https://www.edmonton.ca/sites/default/files/public-files/assets/PDF/Edmonton_Biodiversity_Action_Plan_Final.PDF). In conjunction with the tenants of these plan, this study outlines a long-term environmental monitoring program that also redefines how monitoring is conducted. By implementing zero-emission transportation and employing autonomous recording units, this program will target both noisy and non-noisy and high and low quality habitat areas of Edmonton to monitor the cities' evolving soundscape as infrastructure changes. These efforts align with the city’s broader vision for increased walking and cycling infrastructure, reducing traffic noise, and fostering sustainable practices.

This study aims to assess the proportion of natural areas in Edmonton that exceed noise sensitivity thresholds for both people and biodiversity, mapping these thresholds to guide future urban planning decisions. By shifting infrastructure investments from noise mitigation toward sustainable transit, we can create urban environments that are not only quieter but also more harmonious for both human and wildlife populations. Achieving this vision will position Edmonton as a leader in urban biodiversity preservation, sustainable urban living, and environmental stewardship.

# Methods

```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false
#| include: true
#| fig-align: center
#| fig-cap: Monitoring locations within a 400 m buffer
#| label: fig-monitoring-locations

generate_random_point <- function(centroid, radius = 400) {
  angle <- runif(1, 0, 2 * pi)
  distance <- sqrt(runif(1)) * radius
  new_x <- centroid[1] + distance * cos(angle)
  new_y <- centroid[2] + distance * sin(angle)
  c(new_x, new_y)
}

coe_2025_locs_random <- coe_ini_2025 %>%
  sf::st_coordinates() %>%
  as.data.frame() %>%
  rowwise() %>%
  mutate(random_point = list(generate_random_point(c(X, Y), 500))) %>%
  ungroup() %>%
  mutate(random_point = map(random_point, ~sf::st_point(.x))) %>%
  sf::st_as_sf(coords = c("X", "Y"), crs = sf::st_crs(coe_ini_2025))

coe_2025_random_buffered <- coe_2025_locs_random %>%
  sf::st_buffer(dist = 500)

leaflet() %>%
  addTiles() %>%
  #addMarkers(data = coe_ini_2025, popup = coe_ini_2025$location) %>%
  addPolygons(
    data = coe_2025_random_buffered,
    popup = ~coe_2025_random_buffered$location,
    color = "green",
    fillOpacity = 0.3
  ) %>%
  addMeasure(primaryLengthUnit = "meters", primaryAreaUnit = "sqmeters") %>%
  addMiniMap(position = "bottomleft")
```

## Site selection and study design

The methodology for identifying potential and final monitoring sites was based on a multi-objective framework aligned with the overarching goals of the long-term urban biodiversity and noise monitoring initiative. The study area encompassed the City of Edmonton, with a particular emphasis on its natural areas, urban green spaces, and transitional zones between urban landscapes. This approach aimed to representatively capture spatial heterogeneity in biodiversity and noise levels across the city. To ensure comprehensive data collection, we designed the study to encompass a wide range of land-use types, including residential, commercial, industrial, and recreational areas. By stratifying site selection based on land-use categories and proximity to noise sources such as major roads, railways, and urban green spaces, we sought to capture the full variability of soundscapes. Spatial analysis tools in R, were used to overlay land-use maps with noise modeling data to refine site selection. Additionally, accessibility and logistical considerations were factored into final site selection.

## Acoustic data collection

Acoustic biodiversity data were collected using a mix of Wildlife Acoustics SM4 and SM Mini 2 equipped with stereo-microphone stubs. These devices were selected for their portability, reliability, and ability to record high-fidelity audio across a broad frequency range, enabling the detection of most acoustic biodiversity. The recorders were programmed to capture throughout the day to capture the relative noisescape and during critical periods such as dawn and dusk periods. Recorders were set to record the soundscape for 3 minutes every hour on the hour between 0:00 and 3:00 and 10:00 - 18:00, and every 5 minutes on the hour between 4:00 - 9:00 AM and 19:00 - 23:00. To quantify sound pressure levels, we deployed Convergence Instruments NSRT_mk4 sound level meters which includes a Type 1 digital MEMS microphone. Noise metrics collected included equivalent continuous sound level (*Leq*), maximum and minimum sound levels (*Lmax* and *Lmin*) collected once every minute. Environmental covariates such as temperature, humidity, and vegetation cover were also recorded. ARUs and decibel meters were placed between 1.5 and 3 meters heightand the direction and orientation of the ARUs and decibel meters were recorded.

```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false
#| include: false
#| fig-align: center
#| tbl-cap: Materials needed
#| label: tbl-materials

materials_needed <- tibble(
  category = c(
    "Field Equipment", "Field Equipment", "Field Equipment", "Field Equipment", "Field Equipment", 
    "Field Equipment", "Field Equipment", "Field Equipment", "Field Equipment", "Field Equipment", 
    "Field Equipment", "Field Equipment", "Field Equipment", "Field Equipment", "Field Equipment", 
    "Field Equipment", "Biking Equipment", "Biking Equipment", "Biking Equipment", "Biking Equipment", 
    "Biking Equipment", "Outdoor Gear", "Outdoor Gear", "Outdoor Gear", "Outdoor Gear", "Outdoor Gear"
  ),
  item = c(
    "GPS", "Data sheets", "Compass", "ARU", "Batteries", 
    "SD set file", "Sound meters", "Python cables", "Hose clamps for attachments", "Pencils", 
    "Clipboards", "FLHA Hazard Assessments", "Cell phones", "ERP, FAP and SOP copies", 
    "Quick installation guide", "Screwdriver, screws, nuts and bolts", 
    "Bike", "Bike pumps", "Allen keys", "Goggles", "Helmets", 
    "Gloves", "Outdoor clothing", "Glasses", "Sunscreen", "Reflective Vest"
  )
)

kable(materials_needed)
```

```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false
#| include: false

# Calculated outside R for now
#dem <- st_read("geospatial_assets/DEM/DEM_Points_3TM.shp")
#dem_wgs84 <- st_transform(dem, crs = 4326)
#intersection_result <- st_intersection(dem_wgs84, coe_ini_2025)

veg_areas <- read_csv("geospatial_assets/Vegetation_Areas_-_Naturalized_20250217.csv") |>
  st_as_sf(wkt = "Multipolygon", crs = 4326)

bike_routes <- st_read("geospatial_assets/Bike_Routes/Bike_Routes.shp")

roads <- st_read("geospatial_assets/Roads/Roads.shp")

# Define custom colors: green for "Parks" and purple for others
custom_colors <- c("Parks" = "#4CAF50", "Other" = "#9C27B0") # Vibrant purple for "Other"

# Plot the spatial data with the additional points layer
ggplot(data = veg_areas) +
  geom_sf(aes(fill = ifelse(Maintainer == "Parks", "Parks", "Other")), alpha = 0.7) + # Polygons
  geom_sf(data = bike_routes, aes(color = "grey", size = 1)) +
  geom_sf(data = roads, aes(color = "black", size = 2)) +
  geom_sf(data = coe_ini_2025, aes(color = "Locations"), size = 4) + # Points layer 
  scale_fill_manual(values = custom_colors, name = "Maintainer") +
  scale_color_manual(values = c("Locations" = "blue"), name = "Locations") + # Blue color for points
  theme_minimal() +
  labs(
    title = "Parks Sites, Bike Routes and Initial Locations",
    fill = "Maintainer",
    color = "Legend"
  ) +
  theme(
    legend.position = "bottom",
    plot.title = element_text(size = 16, face = "bold"),
    legend.title = element_text(size = 12)
  )

```

### Sound pressure level equipment and data management

The NSRT_mk4 comes with basic functionalities to record sound pressure levels. Instrument Manager is the devices programmation utility that runs exclusively on Windows. The

When a decibel meter is deployed, securely attach it to something in order to minimize the risk of theft as much as possible. This includes using Python cables, deploying the unit was an unreachable height, or choosing a new deployment location. The decibel meters battery life usually lasts around 1 week after which it will need to be replaced

```{r}
#| include: false
#| echo: false
#| eval: false
#| warning: false
#| message: false

drive_auth()
folder_id <- "1SsB8gepdiqhyFOTkrTe_rdik6A3a9rS1"
folder <- drive_get(as_id(folder_id))
print(folder)

dec <- dir_ls("./spl/date", regexp = ".xls") |>
  map_dfr(
    ~read_csv(.x, skip = 2) |>
      mutate(
        filename = basename(.x),                     
        location = str_extract(filename, "^[^_]+")  
      )
  ) |>
  separate(
    `Time (Date hh:mm:ss.ms)\t L-Max dB -A \t LEQ dB -A \t L-Min dB -A \t L-PeakdB -A`,
    into = c("Time", "L_Max_dB_A", "LEQ_dB_A", "L_Min_dB_A", "L_PeakdB_A"),
    sep = "\t"
  ) |>
  mutate(Time = ymd_hms(Time),
         across(c(L_Max_dB_A, LEQ_dB_A, L_Min_dB_A, L_PeakdB_A), as.numeric))

dec2 <- dir_ls("./spl/time", regexp = ".xls") |>
  map_dfr(
    ~read_csv(.x, skip = 2) |>
      mutate(
        filename = basename(.x),                     
        location = str_extract(filename, "^[^_]+")  
      )
  ) |>
  separate(
    `Time (s)\t L-Max dB -A \t LEQ dB -A \t L-Min dB -A \t L-PeakdB -A`,
    into = c("Time", "L_Max_dB_A", "LEQ_dB_A", "L_Min_dB_A", "L_PeakdB_A"),
    sep = "\t"
  ) |>
  mutate(start_time = str_extract(filename, "\\d{4}_\\d{2}_\\d{2}__\\d{2}h\\d{2}m\\d{2}s") |>
                     str_replace_all("h|m|s", ":") |>
                     ymd_hms(),
         across(c(Time, L_Max_dB_A, LEQ_dB_A, L_Min_dB_A, L_PeakdB_A), as.numeric),
         start_time = start_time + seconds(Time)) |>
  dplyr::select(-Time) |>
  relocate(start_time) |>
  rename(Time = start_time)

dec_f <- bind_rows(dec, dec2)

wl <- wt_get_locations("COE")

wlj <- wl |>
  mutate(location = str_replace_all(location,"-","")) |>
  unnest()

dec_filtered <- dec_f |>
  group_by(location) |>
  mutate(
    Time_minute = floor_date(Time, "minute"),
    is_weekend = wday(Time, label = TRUE) %in% c("Sat", "Sun")  # Add weekend indicator
  ) |> 
  ungroup() |>
  group_by(location, Time_minute) |>
  filter(row_number() == 1) |>
  ungroup() |>
  inner_join(wlj |> dplyr::select(location, latitude, longitude), by = "location")
  

```

```{r}
#| eval: true
# Plot with weekend coloring
ggplot(dec_filtered, aes(x = Time, y = LEQ_dB_A, colour = is_weekend)) +
  geom_point() +
  scale_colour_viridis_d(option = "magma") +
  facet_wrap(~location, ncol = 4) +
  theme_bw() +
  labs(
    title = "LEQ dB-A Over Time by Location",
    x = "Time",
    y = "LEQ dB-A"
  )

dec_filtered <- dec_filtered |> 
  mutate(day_of_week = wday(Time, label = TRUE, abbr = TRUE))

dec_filtered |>
  group_by(location) |>
  summarise(mean = mean(LEQ_dB_A)) |>
  arrange(-mean) |>
  view()

ggplot(dec_filtered |>
         mutate(hour = hour(Time)) |>
         filter(grepl('CAR|KER|RVK',location)) |>
         mutate(is_weekend = ifelse(is_weekend, "Weekend", "Weekday")),  # Convert boolean to character
       aes(x = hour, y = LEQ_dB_A, group = hour, fill = is_weekend)) +
  geom_boxplot() +
  facet_grid(is_weekend ~ location) +
  theme_bw()

```

```{r}
#| eval: true

dec_filtered <- dec_filtered |>
  mutate(hour = hour(Time))  # Add an 'hour' column to easily filter time periods

# Subset data for 6 AM - 9 AM
morning_data <- dec_filtered |>
  filter(hour >= 6 & hour < 9)

# Subset data for the rest of the day (you can choose different time windows)
other_data <- dec_filtered |>
  filter(hour < 6 | hour >= 9)

# Compare average LEQ_dB_A between 6 AM - 9 AM and other times
morning_avg <- mean(morning_data$LEQ_dB_A, na.rm = TRUE)
other_avg <- mean(other_data$LEQ_dB_A, na.rm = TRUE)

# Print averages
cat("Average LEQ during 6AM - 9AM: ", morning_avg, "\n")
cat("Average LEQ during other times of the day: ", other_avg, "\n")

# Perform t-test to check if there's a significant difference
t_test_result <- t.test(morning_data$LEQ_dB_A, other_data$LEQ_dB_A, na.rm = TRUE)

# Print the result of the t-test
print(t_test_result)

dec_filtered <- dec_filtered |>
  mutate(julian = yday(Time))

ggplot(
  dec_filtered |> 
  mutate(hour = hour(Time)),
  aes(x = hour, y = LEQ_dB_A, group = hour, colour = is_weekend)) +
  geom_point() +
  scale_colour_viridis_d(option = "magma", name = "Weekends") +
  theme_bw() +
  facet_wrap(~location) +
  labs(title = "Average Sound Pressure Level Over Time by Location", x = "Hour of the Day", y = "LEQ dB-A")


ggplot(dec_filtered |> 
    mutate(location = case_when(grepl("RVK", location) ~ "Kinnaird Ravine", 
                                grepl("ZOO2", location) ~ "Edmonton Valley Zoo", 
                                grepl("CRY", location) ~ "Crystallina Nera",
                                grepl("DUN", location) ~ "Dunluce",
                                grepl("ROR",location) ~ "Roper Road",
                                TRUE ~ location),
           hour = hour(Time)),
  aes(x = julian, y = LEQ_dB_A, group = julian, fill = is_weekend)) +
  geom_boxplot() +
  scale_fill_viridis_d(option = "magma", name = "Weekends") +
  theme_bw() +
  labs(title = "LEQ dB-A Over Time by Location", x = "Hour of the Day", y = "LEQ dB-A") +
  facet_wrap(~location)

```

```{r}
#| eval: false 
#| include: false

dec_sf <- dec_filtered |>
  st_as_sf(coords = c("longitude", "latitude"), crs = 4326)

grid <- st_make_grid(
  st_bbox(dec_sf),
  cellsize = 1000, # Adjust grid resolution as needed
  what = "centers"
) |> 
  st_as_sf()

grid_df <- grid |> st_coordinates() |> as_tibble()




dec_hourly <- dec_hourly %>%
  filter(latitude >= -90 & latitude <= 90, longitude >= -180 & longitude <= 180) %>%  # Valid coordinates
  mutate(avg_LEQ_dB_A = ifelse(avg_LEQ_dB_A < 0, NA, avg_LEQ_dB_A))  # Remove invalid sound levels

# Debugging: Print summary of the dataset
print(summary(dec_hourly))

# Plot heatmap
heatmap_plot <- ggplot(dec_hourly, aes(x = longitude, y = latitude)) +
  geom_tile(aes(fill = avg_LEQ_dB_A)) +  # Create heatmap
  scale_fill_viridis_c(
    name = "Noise Level (dB-A)",
    option = "magma",
    limits = range(dec_hourly$avg_LEQ_dB_A, na.rm = TRUE),  # Dynamic range
    oob = scales::squish  # Handle values outside range
  ) +
  theme_minimal() +
  coord_fixed() +  # Ensure proper aspect ratio for geographic data
  labs(
    title = "Heatmap of Noise Levels in Edmonton",
    x = "Longitude",
    y = "Latitude"
  )



# Step 2: Convert to sf object and transform to planar coordinates
dec_hourly_sf <- st_as_sf(dec_hourly, coords = c("longitude", "latitude"), crs = 4326)
dec_hourly_sf_planar <- st_transform(dec_hourly_sf, crs = 3857)



```

```{r}
#| eval: false 
#| include: false


# ─── Prepare your sample‐point data for ggplot ─────────────────────────────────
# pts_df is a SpatialPointsDataFrame; extract coords + avg_LEQ into a data.frame:
pts_plot <- data.frame(coordinates(pts_df))
names(pts_plot) <- c("longitude", "latitude")
pts_plot$avg_LEQ <- pts_df$avg_LEQ

# ─── Plot the filled IDW heatmap + sample points ───────────────────────────────
ggplot() +
  # tiled heatmap
  geom_tile(data = idw_df,
            aes(x = x, y = y, fill = pred_LEQ)) +
  # overlay your measurement locations
  geom_point(data = pts_plot,
             aes(x = longitude, y = latitude),
             color = "black", size = 2) +
  scale_fill_viridis_c(name = "Pred LEQ (dB)", na.value = NA) +
  coord_equal() +
  labs(
    title = "Geographic Noise Heatmap (IDW)",
    x     = "Longitude",
    y     = "Latitude"
  ) +
  theme_minimal() +
  theme(
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank()
  )


```

## Acoustic data processing

Acoustic data were transferred to the University of Alberta Data Centre in Edmonton for redundant data storage under [WildTrax](https://wildtrax.ca), which is a national platform for the management, storage, processing, sharing and discovery of environmental sensor data. The recordings were standardized to ensure adherence to the naming convention of `LOCATION_DATETIME`, such as `EDAL-A03-CRY1_20250625_053500.wav`. All recordings designated for processing were directly uploaded to WildTrax and can be downloaded from the platform's Recording tab, accessible under Manage \> Download list of recordings (see @fig-download-recs). Data processing also took place in WildTrax, using the 1SPT method (species-individual per task or time to first detection) with the goal to describe the acoustic community of species heard. The full acoustic community was analyzed including birds, mammals, amphibians, including a relative environment noise assessment (i.e. wind, rain and anthropogenic noise) To ensure balanced replication, four randomly selected recordings were processed for 3-minutes during the morning hours of 5:00 AM - 7:59 AM and dusk hours between 20:00 - 22:59 ideally on four separate dates, during optimal weather conditions. All recordings were simulatenously run through both [BirdNET](https://birdnet.cornell.edu/) and [HawkEars](https://github.com/jhuus/HawkEars) multi-species classifiers to determine false negative and positive rates at the location level for all the media collected, as well as to determine classifier performance.

## Zero-emissions fieldwork

We used [Strava API](https://www.strava.com/settings/api) through [rstrava](https://github.com/fawda123/rStrava) to map the bike trips we took to get to the study locations. We then estimated the city-miles traveled in a gas-powered F-150, a standard vehicle used for city operations. We also calculate the average road infrastructure cost savings performed instead of using vehicles.

Stay tuned for results as they unfold!

```{r}
#| echo: false
#| eval: false
#| warning: false
#| message: false
#| include: false

calculate_f150_co2 <- function(distance_km) {
  # Assumptions
  fuel_efficiency_l_per_100km <- 15.7  # Ford F-150 city fuel efficiency (L/100 km)
  co2_per_liter <- 2.31               # kg CO2 per liter for gasoline
  # Convert distance to fuel consumed (liters)
  fuel_used <- (distance_km / 100) * fuel_efficiency_l_per_100km
  # Calculate CO2 emissions (kg)
  co2_emissions <- fuel_used * co2_per_liter
  return(co2_emissions)
}

distance_km <- 100
co2_emissions <- calculate_f150_co2(distance_km)
co2_emissions

#stoken <- httr::config(token = strava_oauth("emissions", app_client_id = "147439", app_secret = Sys.getenv("STRAVA_SECRET"), app_scope = "activity:read_all"))


#stoken <- httr::config(token = strava_oauth(app_name, app_client_id, app_secret, app_scope="activity:read_all"))
#my_acts <- get_activity_list(stoken, after = as.Date('2020-12-31'))

calculate_savings <- function(daily_km, days_per_year = 250) {
  total_annual_cost <- 462.1e6  
  avg_km_per_vehicle <- 15200   
  num_vehicles <- 700000
  
  # Total annual VKT
  total_vkt <- avg_km_per_vehicle * num_vehicles  # in km
  # Road cost per km
  cost_per_km <- total_annual_cost / total_vkt  # in dollars per km
  # Annual distance biked instead of driven
  annual_biked_km <- daily_km * days_per_year  # in km
  # Annual savings
  savings <- annual_biked_km * cost_per_km  # in dollars
  return(savings)
}

# Example usage
daily_km <- 10
savings <- calculate_savings(daily_km)
print(savings)

```



```{r}

grid <- st_make_grid(
  st_as_sfc(edmonton_bbox),
  cellsize = 0.01,  # 1 km grid cells (0.01 degrees ~ 1 km at mid-latitudes)
  what = "centers"
) %>%
  st_as_sf()

vgm_models <- list(
  "Spherical" = vgm("Sph"),
  "Exponential" = vgm("Exp"),
  "Gaussian" = vgm("Gau")
)

# Fit and plot each model
for (model in names(vgm_models)) {
  vgm_fit <- fit.variogram(variogram_model, model = vgm_models[[model]])
  cat("\n", model, "\n")
  plot(variogram_model, vgm_fit)
}

cv <- krige.cv(
  formula = avg_LEQ_dB_A ~ 1,
  locations = as(dec_hourly_sf, "Spatial"),
  model = vgm_model
)

# Summarize cross-validation results
summary(cv)
plot(cv$observed, cv$predicted, xlab = "Observed", ylab = "Predicted", main = "Cross-Validation")
abline(0, 1, col = "red")

ggplot() +
  geom_sf(data = kriging_result_sf, aes(fill = var1.pred)) +
  geom_sf(data = roads, color = "white", size = 0.2) +
  scale_fill_viridis_c(name = "Predicted Noise (dB-A)", option = "magma") +
  theme_minimal() +
  labs(title = "Predicted Noise Levels") +
  coord_sf()

ggplot() +
  geom_sf(data = kriging_result_sf, aes(fill = var1.var)) +
  geom_sf(data = roads, color = "white", size = 0.2) +
  scale_fill_viridis_c(name = "Prediction Variance", option = "inferno") +
  theme_minimal() +
  labs(title = "Prediction Variance (Uncertainty)") +
  coord_sf()

dec_hourly_grid <- dec_hourly %>%
  mutate(
    lon.group = cut(
      longitude,
      breaks = seq(floor(min(longitude)), ceiling(max(longitude)), by = 0.01),
      labels = seq(floor(min(longitude)) + 0.005, ceiling(max(longitude)), by = 0.01)
    ),
    lat.group = cut(
      latitude,
      breaks = seq(floor(min(latitude)), ceiling(max(latitude)), by = 0.01),
      labels = seq(floor(min(latitude)) + 0.005, ceiling(max(latitude)), by = 0.01)
    )
  ) %>%
  group_by(lon.group, lat.group) %>%
  summarise(
    avg_LEQ_dB_A = mean(avg_LEQ_dB_A, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(across(where(is.factor), ~ as.numeric(as.character(.x))))  # Convert factors to numeric

# Heatmap visualization
heatmap_plot <- ggplot(dec_hourly_grid, aes(x = lon.group, y = lat.group, fill = avg_LEQ_dB_A)) +
  geom_raster() +  # Use raster for grid-like visualization
  scale_fill_viridis_c(name = "Noise Level (dB-A)", option = "magma") +
  coord_fixed() +  # Maintain aspect ratio
  theme_minimal() +
  labs(
    title = "Heatmap of Noise Levels in Edmonton",
    x = "Longitude",
    y = "Latitude"
  )

roads <- st_read("geospatial_assets/Roads/Roads.shp")

dec_hourly_sf <- dec_hourly_grid %>%
  mutate(
    lon = as.numeric(as.character(lon.group)),
    lat = as.numeric(as.character(lat.group))
  ) %>%
  st_as_sf(coords = c("lon", "lat"), crs = 4326)

st_bbox(dec_hourly_sf)
st_bbox(roads)
target_crs <- st_crs(roads)  # Use the CRS of `roads`
dec_hourly_sf <- st_transform(dec_hourly_sf, crs = target_crs)
variogram_model <- variogram(avg_LEQ_dB_A ~ 1, as(dec_hourly_sf, "Spatial"))
vgm_model <- fit.variogram(variogram_model, model = vgm("Sph"))  # Spherical model
plot(variogram_model, vgm_model)

edmonton_bbox <- st_bbox(roads)  # Bounding box of Edmonton
grid <- st_make_grid(
  st_as_sfc(edmonton_bbox), 
  cellsize = 0.001,  # Adjust cell size for resolution
  what = "centers"
) %>%
  st_as_sf()

# Clip the grid to the bounding box of Edmonton or roads
grid <- st_intersection(grid, st_as_sfc(edmonton_bbox))

kriging_result <- krige(
  formula = avg_LEQ_dB_A ~ 1, 
  locations = as(dec_hourly_sf, "Spatial"), 
  newdata = as(grid, "Spatial"), 
  model = vgm_model
)

# Convert the result back to an sf object
kriging_result_sf <- st_as_sf(kriging_result)

ggplot() +
  geom_sf(data = kriging_result_sf, aes(fill = var1.pred)) +
  geom_sf(data = roads, color = "white") +
  scale_fill_viridis_c(option = "magma") +
  theme_minimal()

road_buffer <- st_buffer(roads, dist = 50)  # Example buffer
distance_to_roads <- st_distance(grid, road_buffer)

# Include as a covariate in kriging
kriging_result <- krige(
  formula = avg_LEQ_dB_A ~ distance_to_roads,
  locations = as(dec_hourly_sf, "Spatial"),
  newdata = as(grid, "Spatial"),
  model = vgm_model
)

```
















